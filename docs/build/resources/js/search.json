[[{"l":"Autoencoders","p":["Autoencoders (AE) are type of artificial neural network that aims to copy their inputs to their outputs . They work by compressing the input into a latent-space representation also known as bottleneck, and then reconstructing the output from this representation. Autoencoder is an unsupervised machine learning algorithm. We can define autoencoder as feature extraction algorithm.","The input data may be in the form of speech, text, image, or video. An Autoencoder finds a representation or code in order to perform useful transformations on the input data."]},{"l":"Idea behind Autoencoders","p":["Data compression is a big topic that’s used in computer vision, computer networks, computer architecture, and many other fields. The point of data compression is to convert our input into a smaller(Latent Space) representation that we recreate, to a degree of quality. This smaller representation is what would be passed around, and, when anyone needed the original, they would reconstruct it from the smaller representation","An autoencoder takes an image as input, stores it in a lower dimension, and tries to reproduce the same image as output, hence the term auto(which stands for being able to reproduce the input). However, if we just reproduce the input in the output, we would not need a network, but a simple multiplication of the input by 1 would do. The differentiating aspect of an autoencoder is that it encodes the information present in an image in a lower dimension and then reproduces the image, hence the term encoder(which stands for representing the information of an image in a lower dimension). This way, images that are similar will have similar encoding. Further, the decoder works towards reconstructing the original image from the encoded vector.","A simple architecture of Autoencoder"]},{"l":"Components of Autoencoder","p":["An autoencoder has three main components, each playing a crucial role in its ability to learn and compress data:","Encoder: This is the \"bottleneck\" of the autoencoder and is responsible for transforming the input data into a lower-dimensional latent space representation. It usually consists of several neural network layers (fully connected, convolutional, etc.) that progressively condense the information while capturing the essential features of the input. The complexity of the encoder depends on the specific application and the type of data being processed.","Latent Space: This is the compressed representation of the input data extracted by the encoder. It serves as a bridge between the input and output, capturing the core information in a more compact form. The dimensionality of the latent space is crucial, as it defines the level of compression and the type of features the autoencoder learns.","Decoder: This component \"decodes\" the latent space representation back into an output that resembles the original input data. It typically mirrors the architecture of the encoder but in reverse, gradually expanding the dimensionality of the representation until it reaches the original input size. The decoder's goal is to minimize the difference between the original input and the reconstructed output, allowing the autoencoder to learn a faithful representation of the data.","Additional components:","Loss function: This function quantifies the discrepancy between the original input and the reconstructed output. Common choices include mean squared error and cross-entropy.","Optimizer: This algorithm guides the network parameters towards minimizing the loss function and improving the autoencoder's performance. Popular optimizers include Adam and SGD."]},{"l":"Properties of Autoencoder","p":["Autoencoders are data-specific, which means that they will only be able to compress data similar to what they have been trained on. Example, an autoencoder trained on pictures of faces would do a rather poor job of compressing pictures of trees, because the features it would learn would be face-specific.","Autoencoders are lossy, which means that the decompressed outputs will be degraded compared to the original inputs.","Autoencoders are learned automatically from data examples, which is a useful property: it means that it is easy to train specialized instances of the algorithm that will perform well on a specific type of input. It doesn’t require any new engineering, just appropriate training data."]},{"i":"why-use-autoencoders","l":"Why use Autoencoders?","p":["Anomaly detection:","Data augmentation and pre-training:","Explainable AI:","Fraud detection: By analyzing financial transactions through an autoencoder, anomalies like fraudulent activities can be flagged based on deviations from the learned normal patterns.","Generative tasks:","Identifying key features: By analyzing the sensitivity of the reconstructed output to changes in the latent space, we can identify the most important features the autoencoder has learned from the data.","Image inpainting: Missing or corrupted parts of images can be reconstructed by an autoencoder trained on similar images, effectively \"filling in the blanks.\" Artistic style transfer: The artistic style of one image can be applied to another image using autoencoders to transfer the characteristic features and brushstrokes.","Medical diagnosis: Medical images like X-rays or MRI scans can be analyzed by autoencoders to detect abnormalities like tumors or lesions based on their deviation from the healthy learned representation.","Music generation: By learning the underlying patterns of music data, autoencoders can generate new pieces of music in similar styles.","Network intrusion detection: Similar to fraud detection, autoencoders can learn the normal traffic patterns in a network and identify intrusions as anomalous data points.","News articles or document summarization: An autoencoder trained on a large corpus of text can learn to capture the essential meaning of a document and generate a concise summary.","Pre-training model features: The latent space representation learned by an autoencoder can be used as pre-trained features for other deep learning models, improving their performance on various tasks.","Synthetic data generation: For tasks where limited data is available, autoencoders can be used to generate synthetic data by learning the underlying distribution of the existing data.","Text summarization and topic modeling:","These are just a few examples, and the potential applications of autoencoders continue to expand as researchers explore their capabilities further.","Topic modeling: Identifying hidden thematic structures within large collections of text documents becomes easier with autoencoders. The latent space representation can reveal clusters of documents with similar topics.","Visualizing data insights: The latent space of an autoencoder can be visualized to understand the underlying structure and relationships within the data, providing insights into the model's decision-making process."]}],[{"l":"Noise removal from plant leaf images"},{"l":"Abstract","p":["This autoencoder-based study proposes a novel methodology for noise removal in plant leaf images, enhancing subsequent analysis for disease detection, species identification, stress response assessment and efficient storage of information. The compressed latent space representation learned by the autoencoder effectively filters noise while preserving vital leaf features, leading to improved accuracy and deeper insights into plant health and environmental interactions."]},{"l":"Data preparation","p":["ignore warnings:","Suppresses all warning messages during the execution of the subsequent code by setting the warning filter to \"ignore.\"","Loading the data","These lines of code set up four datasets with specified transformations for training and testing, each consisting of pairs of noisy and pure plant images. These datasets is used for training and evaluating our Autoencoder","The transformations that are applied to the dataset are:","convert the image to (128, 128)","convert the values to tensor"]},{"l":"Visualize Images"},{"l":"Pure Images","p":["Visualize 9 images from the pure dataset in 3x3 grid","Pure Image"]},{"l":"Noisy Images","p":["Visualize 9 images from the noisy dataset in 3x3 grid","Noisy Image"]},{"l":"Model Building"},{"l":"Encoder Decoder Architecture","p":["The __init__ method initializes the Autoencoder's architecture. The encoder is a sequential stack of fully connected (linear) layers with ReLU activation functions, reducing the input size from 49152 to 5.","The decoder is another sequential stack of fully connected layers with ReLU activations, reconstructing the input size back to 49152. The architecture mirrors the encoder but in reverse order.","The forward method defines the forward pass of the autoencoder. It takes an input tensor x, which is reshaped to flatten its spatial dimensions. The flattened input is passed through the encoder(self.encoder), producing a latent representation y. The latent representation is then passed through the decoder(self.decoder), reconstructing the output z. The final output is reshaped to have the original spatial dimensions (3 channels, 128x128 pixels).","The reconstructed output z represents the autoencoder's attempt to reconstruct the input, and this is what the model aims to optimize during training."]},{"l":"Testing and Evaluation of model","p":["Before we start to training of our model, we have define an optimizer and the loss function for our model to use"]},{"l":"Check for GPU Availability"},{"l":"Loss function and Optimizer Initialzation"},{"l":"Model training loop"},{"l":"Model Evaluation Loop"},{"l":"Visualize the Denoised Images","p":["Plot the original noisy images","Orignal Noisy Images","Plot the denoised images which are saved in the directory","Denoised Images saved in the directory"]},{"l":"Evaluation of our model","p":["Now we are evaluating our Autoencoder model, in evaluation mode on a test dataset using a test_loader. It computes the loss between the model's predictions and the ground truth data provided by a ground_loader. The losses are printed for each batch in the test set, helping to assess the model's performance on the test data. The model has been previously set to evaluation mode (model.eval()) to ensure consistent behavior during evaluation."]},{"i":"visualize-images-1","l":"Visualize images"}],[{"l":"Team","p":["What should go here ??"]}]]