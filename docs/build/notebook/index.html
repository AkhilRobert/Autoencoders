<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="turbo-cache-control" content="no-cache" data-turbo-track="reload" data-track-token="3.5.0.758568667634">

    <!-- See retype.com -->
    <meta name="generator" content="Retype 3.5.0">

    <!-- Primary Meta Tags -->
    <title>Noise removal from plant leaf images</title>
    <meta name="title" content="Noise removal from plant leaf images">
    <meta name="description" content="This autoencoder-based study proposes a novel methodology for noise removal in plant leaf images, enhancing subsequent analysis for disease...">

    <!-- Canonical -->
    <link rel="canonical" href="https://gan-hw9r.onrender.com/notebook/">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://gan-hw9r.onrender.com/notebook/">
    <meta property="og:title" content="Noise removal from plant leaf images">
    <meta property="og:description" content="This autoencoder-based study proposes a novel methodology for noise removal in plant leaf images, enhancing subsequent analysis for disease...">
    <meta property="og:image" content="https://gan-hw9r.onrender.com/images/pure.png">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://gan-hw9r.onrender.com/notebook/">
    <meta property="twitter:title" content="Noise removal from plant leaf images">
    <meta property="twitter:description" content="This autoencoder-based study proposes a novel methodology for noise removal in plant leaf images, enhancing subsequent analysis for disease...">
    <meta property="twitter:image" content="https://gan-hw9r.onrender.com/images/pure.png">

    <script data-cfasync="false">(function () { var el = document.documentElement, m = localStorage.getItem("doc_theme"), wm = window.matchMedia; if (m === "dark" || (!m && wm && wm("(prefers-color-scheme: dark)").matches)) { el.classList.add("dark") } else { el.classList.remove("dark") } })();</script>

    <link href="../resources/css/retype.css?v=3.5.0.758568667634" rel="stylesheet">

    <script data-cfasync="false" src="../resources/js/config.js?v=3.5.0.758568667634" data-turbo-eval="false" defer></script>
    <script data-cfasync="false" src="../resources/js/retype.js?v=3.5.0" data-turbo-eval="false" defer></script>
    <script id="lunr-js" data-cfasync="false" src="../resources/js/lunr.js?v=3.5.0.758568667634" data-turbo-eval="false" defer></script>
    <script id="prism-js" data-cfasync="false" src="../resources/js/prism.js?v=3.5.0.758568667634" defer></script>
</head>
<body>
    <div id="docs-app" class="relative text-base antialiased text-gray-700 bg-white font-body dark:bg-dark-850 dark:text-dark-300">
        <div class="absolute bottom-0 left-0 bg-gray-100 dark:bg-dark-800" style="top: 5rem; right: 50%"></div>
    
        <header id="docs-site-header" class="sticky top-0 z-30 flex w-full h-16 bg-white border-b border-gray-200 md:h-20 dark:bg-dark-850 dark:border-dark-650">
            <div class="container relative flex items-center justify-between pr-6 grow md:justify-start">
                <!-- Mobile menu button skeleton -->
                <button v-cloak class="skeleton docs-mobile-menu-button flex items-center justify-center shrink-0 overflow-hidden dark:text-white focus:outline-none rounded-full w-10 h-10 ml-3.5 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" class="mb-px shrink-0" width="24" height="24" viewBox="0 0 24 24" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor"><path d="M2 4h20v2H2zM2 11h20v2H2zM2 18h20v2H2z"></path></g></svg></button>
                <div v-cloak id="docs-sidebar-toggle"></div>
        
                <!-- Logo -->
                <div class="flex items-center justify-between h-full py-2 md:w-75">
                    <div class="flex items-center px-2 md:px-6">
                        <a id="docs-site-logo" href="../" class="flex items-center leading-snug text-2xl">
                            <span class="dark:text-white font-semibold line-clamp-1 md:line-clamp-2">Autoencoders</span>
                        </a>
                    </div>
        
                    <span class="hidden h-8 border-r md:inline-block dark:border-dark-650"></span>
                </div>
        
                <div class="flex justify-between md:grow">
                    <!-- Top Nav -->
                    <nav class="hidden md:flex">
                        <ul class="flex flex-col mb-4 md:pl-16 md:mb-0 md:flex-row md:items-center">
                            
                        </ul>
                    </nav>
        
                    <!-- Header Right Skeleton -->
                    <div v-cloak class="flex justify-end grow skeleton">
        
                        <!-- Search input mock -->
                        <div class="relative hidden w-40 lg:block lg:max-w-sm lg:ml-auto">
                            <div class="absolute flex items-center justify-center h-full pl-3 dark:text-dark-300">
                                <svg xmlns="http://www.w3.org/2000/svg" class="icon-base" width="16" height="16" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 1px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                            </div>
                            <input class="w-full h-10 placeholder-gray-400 transition-colors duration-200 ease-in bg-gray-200 border border-transparent rounded md:text-sm hover:bg-white hover:border-gray-300 focus:outline-none focus:bg-white focus:border-gray-500 dark:bg-dark-600 dark:border-dark-600 dark:placeholder-dark-400" style="padding: 0.625rem 0.75rem 0.625rem 2rem" type="text" placeholder="Search">
                        </div>
        
                        <!-- Mobile search button -->
                        <div class="flex items-center justify-center w-10 h-10 lg:hidden">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="20" height="20" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                        </div>
        
                        <!-- Dark mode switch placeholder -->
                        <div class="w-10 h-10 lg:ml-2"></div>
        
                        <!-- History button -->
                        <div class="flex items-center justify-center w-10 h-10" style="margin-right: -0.625rem;">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="22" height="22" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><g ><path d="M12.01 6.01c-.55 0-1 .45-1 1V12a1 1 0 00.4.8l3 2.22a.985.985 0 001.39-.2.996.996 0 00-.21-1.4l-2.6-1.92V7.01c.02-.55-.43-1-.98-1z"></path><path d="M12.01 1.91c-5.33 0-9.69 4.16-10.05 9.4l-.29-.26a.997.997 0 10-1.34 1.48l1.97 1.79c.19.17.43.26.67.26s.48-.09.67-.26l1.97-1.79a.997.997 0 10-1.34-1.48l-.31.28c.34-4.14 3.82-7.41 8.05-7.41 4.46 0 8.08 3.63 8.08 8.09s-3.63 8.08-8.08 8.08c-2.18 0-4.22-.85-5.75-2.4a.996.996 0 10-1.42 1.4 10.02 10.02 0 007.17 2.99c5.56 0 10.08-4.52 10.08-10.08.01-5.56-4.52-10.09-10.08-10.09z"></path></g></g></svg>
                        </div>
                    </div>
        
                    <div v-cloak class="flex justify-end grow">
                        <div id="docs-mobile-search-button"></div>
                        <doc-search-desktop></doc-search-desktop>
        
                        <doc-theme-switch class="lg:ml-2"></doc-theme-switch>
                        <doc-history></doc-history>
                    </div>
                </div>
            </div>
        </header>
    
        <div class="container relative flex bg-white">
            <!-- Sidebar Skeleton -->
            <div v-cloak class="fixed flex flex-col shrink-0 duration-300 ease-in-out bg-gray-100 border-gray-200 sidebar top-20 w-75 border-r h-screen md:sticky transition-transform skeleton dark:bg-dark-800 dark:border-dark-650">
            
                <!-- Render this div, if config.showSidebarFilter is `true` -->
                <div class="flex items-center h-16 px-6">
                    <input class="w-full h-8 px-3 py-2 transition-colors duration-200 ease-linear bg-white border border-gray-200 rounded shadow-none text-sm focus:outline-none focus:border-gray-600 dark:bg-dark-600 dark:border-dark-600" type="text" placeholder="Filter">
                </div>
            
                <div class="pl-6 mt-1 mb-4">
                    <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-32 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-48 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                    <div class="w-40 h-3 mb-4 bg-gray-200 rounded-full loading dark:bg-dark-600"></div>
                </div>
            
                <div class="shrink-0 mt-auto bg-transparent dark:border-dark-650">
                    <a class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                        <span class="text-xs whitespace-nowrap">Powered by</span>
                        <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                    </a>
                </div>
            </div>
            
            <!-- Sidebar component -->
            <doc-sidebar v-cloak>
                <template #sidebar-footer>
                    <div class="shrink-0 mt-auto border-t md:bg-transparent md:border-none dark:border-dark-650">
            
                        <a class="flex items-center justify-center flex-nowrap h-16 text-gray-400 dark:text-dark-400 hover:text-gray-700 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                            <span class="text-xs whitespace-nowrap">Powered by</span>
                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                        </a>
                    </div>
                </template>
            </doc-sidebar>
    
            <div class="grow min-w-0 dark:bg-dark-850">
                <!-- Render "toolbar" template here on api pages --><!-- Render page content -->
                <div class="flex">
                    <div class="min-w-0 p-4 grow md:px-16">
                        <main class="relative pb-12 lg:pt-2">
                            <div class="docs-markdown" id="docs-content">
                                <!-- Rendered if sidebar right is enabled -->
                                <div id="docs-sidebar-right-toggle"></div>
                                <!-- Page content  -->
<doc-anchor-target id="noise-removal-from-plant-leaf-images" class="break-words">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#noise-removal-from-plant-leaf-images">#</doc-anchor-trigger>
        <span>Noise removal from plant leaf images</span>
    </h1>
</doc-anchor-target>
<hr>
<doc-anchor-target id="abstract">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#abstract">#</doc-anchor-trigger>
        <span>Abstract</span>
    </h2>
</doc-anchor-target>
<p>This autoencoder-based study proposes a novel methodology for noise removal in plant leaf images, enhancing subsequent analysis for disease detection, species identification, stress response assessment and efficient storage of information. The compressed latent space representation learned by the autoencoder effectively filters noise while preserving vital leaf features, leading to improved accuracy and deeper insights into plant health and environmental interactions.</p>
<hr>
<doc-anchor-target id="data-preparation">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#data-preparation">#</doc-anchor-trigger>
        <span>Data preparation</span>
    </h2>
</doc-anchor-target>
<p><strong>ignore warnings:</strong></p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">import warnings
warnings.filterwarnings(&quot;ignore&quot;)</code></pre>
</doc-codeblock></div>
<p>Suppresses all warning messages during the execution of the subsequent code by setting the warning filter to &quot;ignore.&quot;</p>
<p><strong>Loading the data</strong></p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">from torchvision.datasets import ImageFolder
from torchvision.transforms import Compose, Resize, ToTensor

transf = Compose([Resize((128, 128)), ToTensor()])
noise_train = ImageFolder(&quot;./PlantVillage/Noisy_Dataset/Train_Data/&quot;, transform=transf)
pure_train = ImageFolder(&quot;./PlantVillage/Pure_Dataset/Train_Data/&quot;, transform=transf)
noise_test = ImageFolder(&quot;./PlantVillage/Noisy_Dataset/Test_Data/&quot;, transform=transf)
pure_test = ImageFolder(&quot;./PlantVillage/Pure_Dataset/Test_Data/&quot;, transform=transf)</code></pre>
</doc-codeblock></div>
<p>These lines of code set up four datasets with specified transformations for training and testing, each consisting of pairs of noisy and pure plant images. These datasets is used for training and evaluating our Autoencoder</p>
<p>The transformations that are applied to the dataset are:</p>
<ul>
<li>convert the image to <code v-pre>(128, 128)</code></li>
<li>convert the values to tensor</li>
</ul>
<doc-anchor-target id="visualize-images">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#visualize-images">#</doc-anchor-trigger>
        <span>Visualize Images</span>
    </h2>
</doc-anchor-target>
<doc-anchor-target id="pure-images">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#pure-images">#</doc-anchor-trigger>
        <span>Pure Images</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">import matplotlib.pyplot as plt

for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.axis(&quot;off&quot;)
    plt.imshow(images_pure[i], cmap=&quot;gray&quot;)</code></pre>
</doc-codeblock></div>
<p>Visualize 9 images from the pure dataset in 3x3 grid</p>
<p><figure class="content-center">
    <img src="../images/pure.png" alt="Pure Image">
    <figcaption class="caption">Pure Image</figcaption>
</figure>
</p>
<doc-anchor-target id="noisy-images">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#noisy-images">#</doc-anchor-trigger>
        <span>Noisy Images</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.axis(&quot;off&quot;)
    plt.imshow(images_test[i], cmap=&quot;gray&quot;)</code></pre>
</doc-codeblock></div>
<p>Visualize 9 images from the noisy dataset in 3x3 grid</p>
<p><figure class="content-center">
    <img src="../images/noisy.png" alt="Noisy Image">
    <figcaption class="caption">Noisy Image</figcaption>
</figure>
</p>
<hr>
<doc-anchor-target id="model-building">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#model-building">#</doc-anchor-trigger>
        <span>Model Building</span>
    </h2>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">from torch import nn

class AutoEncoder(nn.Module):
    def __init__(self):
        super(AutoEncoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(49152, 5000),
            nn.ReLU(),
            nn.Linear(5000, 500),
            nn.ReLU(),
            nn.Linear(500, 50),
            nn.ReLU(),
            nn.Linear(50, 5),
        )
        self.decoder = nn.Sequential(
            nn.Linear(5, 50),
            nn.ReLU(),
            nn.Linear(50, 500),
            nn.ReLU(),
            nn.Linear(500, 5000),
            nn.ReLU(),
            nn.Linear(5000, 49152),
        )

    def forward(self, x):
        x = x.view(x.size(0), -1)
        y = self.encoder(x)
        z = self.decoder(y)
        z = z.view(z.size(0), 3, 128, 128)
        return z</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="encoder-decoder-architecture">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#encoder-decoder-architecture">#</doc-anchor-trigger>
        <span>Encoder Decoder Architecture</span>
    </h3>
</doc-anchor-target>
<p>The <code v-pre>__init__</code> method initializes the <strong>Autoencoder&#x27;s architecture</strong>. The <strong>encoder</strong> is a sequential stack of fully connected (linear) layers with <code v-pre>ReLU</code> activation functions, reducing the input size from <code v-pre>49152</code> to <code v-pre>5</code>.</p>
<p>The <strong>decoder</strong> is another sequential stack of fully connected layers with ReLU activations, reconstructing the input size back to <code v-pre>49152</code>. The architecture mirrors the encoder but in reverse order.</p>
<p>The forward method defines the forward pass of the autoencoder. It takes an input tensor <code v-pre>x</code>, which is reshaped to flatten its spatial dimensions.
The flattened input is passed through the <strong>encoder</strong> (self.encoder), producing a latent representation <code v-pre>y</code>.
The latent representation is then passed through the <strong>decoder</strong> (self.decoder), reconstructing the output <code v-pre>z</code>.
The final output is reshaped to have the original spatial dimensions <code v-pre>(3 channels, 128x128 pixels)</code>.</p>
<p>The reconstructed output z represents the autoencoder&#x27;s attempt to reconstruct the input, and this is what the model aims to optimize during training.</p>
<doc-anchor-target id="testing-and-evaluation-of-model">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#testing-and-evaluation-of-model">#</doc-anchor-trigger>
        <span>Testing and Evaluation of model</span>
    </h2>
</doc-anchor-target>
<p>Before we start to training of our model, we have define an optimizer and the loss function for our model to use</p>
<doc-anchor-target id="check-for-gpu-availability">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#check-for-gpu-availability">#</doc-anchor-trigger>
        <span>Check for GPU Availability</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
print(&quot;Using PyTorch version:&quot;, torch.__version__, &quot;CUDA:&quot;, torch.cuda.is_available())</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="loss-function-and-optimizer-initialzation">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#loss-function-and-optimizer-initialzation">#</doc-anchor-trigger>
        <span>Loss function and Optimizer Initialzation</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">model = AutoEncoder().to(device)
loss_func = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.002)</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="model-training-loop">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#model-training-loop">#</doc-anchor-trigger>
        <span>Model training loop</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">from tqdm import tqdm

make_dir()
EPOCH = 5
for epoch in range(EPOCH):
    with tqdm(
        total=len(train_loader), desc=f&quot;Epoch {epoch + 1}&quot;, unit=&quot;batch&quot;
    ) as epoch_progress_bar:
        for x, y in zip(train_loader, pure_loader):
            t_x, _ = x
            t_x = t_x.to(device)
            t_y, label = y
            t_y = t_y.to(device)
            optimizer.zero_grad()
            decoded1 = model(t_x)
            loss = loss_func(decoded1, t_y)
            train_loss = loss.item()
            loss.backward()
            optimizer.step()
            epoch_progress_bar.set_postfix(train_loss=train_loss)
            epoch_progress_bar.update(1)
        epoch_progress_bar.close()</code></pre>
</doc-codeblock></div>
<doc-anchor-target id="model-evaluation-loop">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#model-evaluation-loop">#</doc-anchor-trigger>
        <span>Model Evaluation Loop</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">model.eval()
total_loss = 0.0
for batch_idx, (x, y) in enumerate(zip(train_loader, pure_loader)):
    t_x, _ = x
    eval_x = t_x.to(device)
    t_y, _ = y
    eval_y = t_y.to(device)
    decoded2 = model(eval_x)
    loss = loss_func(decoded2, eval_y)
    print(loss)
    total_loss += loss.item()
    for i in range(len(decoded2)):
        save_pic(
            decoded2[i].cpu().data, name=f&quot;./PlantVillage/Denoised_Images/ae_{i}.jpg&quot;
        )</code></pre>
</doc-codeblock></div>
<hr>
<doc-anchor-target id="visualize-the-denoised-images">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#visualize-the-denoised-images">#</doc-anchor-trigger>
        <span>Visualize the Denoised Images</span>
    </h2>
</doc-anchor-target>
<p>Plot the original noisy images</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">for i in range(64):
    plt.subplot(8, 8, i + 1)
    plt.axis(&quot;off&quot;)
    plt.imshow(images_arr[i], cmap=&quot;gray&quot;)</code></pre>
</doc-codeblock></div>
<p><figure class="content-center">
    <img src="../images/denoised-org.png" alt="Orignal Noisy Images">
    <figcaption class="caption">Orignal Noisy Images</figcaption>
</figure>
</p>
<p>Plot the denoised images which are saved in the directory</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">data = glob(&quot;./PlantVillage/Denoised_Images/*.jpg&quot;)
images_denoised = [imread(img) for img in data]
for i in range(16):
    plt.subplot(4, 4, i + 1)
    plt.axis(&quot;off&quot;)
    plt.imshow(images_denoised[i], cmap=&quot;gray&quot;)</code></pre>
</doc-codeblock></div>
<p><figure class="content-center">
    <img src="../images/denoised-org.png" alt="Denoised Images saved in the directory">
    <figcaption class="caption">Denoised Images saved in the directory</figcaption>
</figure>
</p>
<hr>
<doc-anchor-target id="evaluation-of-our-model">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#evaluation-of-our-model">#</doc-anchor-trigger>
        <span>Evaluation of our model</span>
    </h2>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">model.eval()
for x, y in zip(test_loader, ground_loader):
    t_x, _ = x
    eval_x = t_x.to(device)
    t_y, _ = y
    eval_y = t_y.to(device)
    decoded2 = model(eval_x)
    loss = loss_func(decoded2, eval_y)
    print(loss)</code></pre>
</doc-codeblock></div>
<p>Now we are evaluating our <code v-pre>Autoencoder model</code>, in evaluation mode on a test dataset using a test_loader. It computes the loss between the model&#x27;s predictions and the ground truth data provided by a ground_loader. The losses are printed for each batch in the test set, helping to assess the model&#x27;s performance on the test data. The model has been previously set to evaluation mode (model.eval()) to ensure consistent behavior during evaluation.</p>
<doc-anchor-target id="visualize-images-1">
    <h3>
        <doc-anchor-trigger class="header-anchor-trigger" to="#visualize-images-1">#</doc-anchor-trigger>
        <span>Visualize images</span>
    </h3>
</doc-anchor-target>
<div class="codeblock-wrapper"><doc-codeblock>
<pre class="language-python"><code v-pre class="language-python">for i in range(64):
    plt.subplot(8, 8, i + 1)
    plt.axis(&quot;off&quot;)
    plt.imshow(images_ground[i], cmap=&quot;gray&quot;)</code></pre>
</doc-codeblock></div>
<p><figure class="content-center">
    <img src="../images/final.png" alt="">
    <figcaption class="caption"></figcaption>
</figure>
</p>

                                
                                <!-- Required only on API pages -->
                                <doc-toolbar-member-filter-no-results></doc-toolbar-member-filter-no-results>
                            </div>
                            <footer class="clear-both">
                            
                                <nav class="flex mt-14">
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 h-full flex items-center break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-l-lg transition-colors duration-150 relative hover:z-5" href="../">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mr-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19 11H7.41l5.29-5.29a.996.996 0 10-1.41-1.41l-7 7a1 1 0 000 1.42l7 7a1.024 1.024 0 001.42-.01.996.996 0 000-1.41L7.41 13H19c.55 0 1-.45 1-1s-.45-1-1-1z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                            <span>
                                                <span class="block text-xs font-normal text-gray-400 dark:text-dark-400">Previous</span>
                                                <span class="block mt-1">Autoencoders</span>
                                            </span>
                                        </a>
                                    </div>
                            
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 -mx-px h-full flex items-center justify-end break-normal font-medium text-blue-500 dark:text-blue-400 border border-gray-300 hover:border-gray-400 dark:border-dark-650 dark:hover:border-dark-450 rounded-r-lg transition-colors duration-150 relative hover:z-5" href="../team/">
                                            <span>
                                                <span class="block text-xs font-normal text-right text-gray-400 dark:text-dark-400">Next</span>
                                                <span class="block mt-1"></span>
                                            </span>
                                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19.92 12.38a1 1 0 00-.22-1.09l-7-7a.996.996 0 10-1.41 1.41l5.3 5.3H5c-.55 0-1 .45-1 1s.45 1 1 1h11.59l-5.29 5.29a.996.996 0 000 1.41c.19.2.44.3.7.3s.51-.1.71-.29l7-7c.09-.09.16-.21.21-.33z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                        </a>
                                    </div>
                                </nav>
                            </footer>
                        </main>
                
                        <div class="border-t dark:border-dark-650 pt-6 mb-8">
                            <footer class="flex flex-wrap items-center justify-between">
                                <div>
                                    <ul class="flex flex-wrap items-center text-sm">
                                    </ul>
                                </div>
                                <div class="docs-copyright py-2 text-gray-500 dark:text-dark-350 text-sm leading-relaxed"><p>Â© Copyright 2024. All rights reserved.</p></div>
                            </footer>
                        </div>
                    </div>
                
                    <!-- Rendered if sidebar right is enabled -->
                    <!-- Sidebar right skeleton-->
                    <div v-cloak class="fixed top-0 bottom-0 right-0 translate-x-full bg-white border-gray-200 lg:sticky lg:border-l lg:shrink-0 lg:pt-6 lg:transform-none sm:w-1/2 lg:w-64 lg:z-0 md:w-104 sidebar-right skeleton dark:bg-dark-850 dark:border-dark-650">
                        <div class="pl-5">
                            <div class="w-32 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                            <div class="w-48 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                            <div class="w-40 h-3 mb-4 bg-gray-200 dark:bg-dark-600 rounded-full loading"></div>
                        </div>
                    </div>
                
                    <!-- User should be able to hide sidebar right -->
                    <doc-sidebar-right v-cloak></doc-sidebar-right>
                </div>

            </div>
        </div>
    
        <doc-search-mobile></doc-search-mobile>
        <doc-back-to-top></doc-back-to-top>
    </div>


    <div id="docs-overlay-target"></div>

    <script data-cfasync="false">window.__DOCS__ = { "title": "Noise removal from plant leaf images", level: 1, icon: "file", hasPrism: true, hasMermaid: false, hasMath: false, tocDepth: 23 }</script>
</body>
</html>
